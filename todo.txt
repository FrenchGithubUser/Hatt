handle websites which require a cookie to display images (ex : vimm)
-> or add a scraper for each category to add images when they are missing

publish to aur (-git version)

think about how to handle pagination

handle websites that have 'background-image' in style to extract the image's url (in scrapePlainHtml.go)

select criterias to sort sources (quality, speed, captchas, premium hosts etc)

create post-processors for websites which have multiple categories. the post processor would take all the search results 
and only return the ones relevent to the selected categories

add comments in the code to make it more readable

set logging levels with some prints

add reddit/discord liks in header


sites :

https://uhdmovies.vip/ //a few redirects but up to 4K quality in ddl

Nxmac.com , cmacked.com , macbed.com //mac apps/games

https://cpgrepacks.site/

https://watchcartoonsonline.eu
